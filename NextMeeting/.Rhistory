length(we8thereCounts[1,])
dim(B)
head(B)
dim(B)
length(we8thereCounts[1,])
length(we8thereCounts[,1])
dim(B)
head(B)
dim(B)[2]
dim(B)[1]
head(B)
head(B)[1]
head(B)[1,]
head(B)[1,]
head(B)[1,]
dim(head(B))
head(B)
B[1,]
B[,1]
B
qz <- we8thereCounts%*%t(B[3:6,])   #this is still correct for the first part.
qz
dim(qz)
B
we8thereRatings
we8thereRatings['Overall']
B
B[1,]
B[1,]
B[5,]
B[50,]
B[1,]
B[2,] * we8thereRatings['Overall']
dim(B)
Y
clusters = Y[,2:5]
clusters
clusters %*% B[3:6,]
matrix(clusters) %*% B[3:6,]
B[3:6,]
B[3:6,] %*% clusters
dim(clusters)
dim(B[3:6,])
dim(b[2,])
B[2,]
B
dim(Y)
B
B[2,]
length(B[,2])
length(B[2,])
dim(Y)
y
B[2,] * Y[1,]
B[2,]
Y[,1]
B[2,] * Y[,1]
length(B[2,])
B[2,]*Y[1,1]
i = 1
b = B
const = b[1,] + b[2,]*y[i] #this doesn't depend on the cluster
head(Y)
y = Y[1,]
y
y = Y[,1]
const = b[1,] + b[2,]*y[i] #this doesn't depend on the cluster
const
dim(const)
length(const)
b[2,]*y
length(b[2,])
matrix(b[2,])
t(matrix(b[2,]))
t(matrix(b[2,])) %*% y
dim(t(matrix(b[2,])))
(t(matrix(b[2,]))) %*% matrix(y)
dim(matrix(y0))
dim(matrix(y))
dim(y0)
dim(y)
matrix(b) %*% matrix(y)
dim(matrix(y))
matrix(b) %*% t(matrix(y))
hm<-matrix(b) %*% t(matrix(y))
dim(hm)
hm<-matrix(b[2,]) %*% t(matrix(y))
dim(hm)
dim(b[1,])
b[1,]
b[1,]+hm
yay <- b[1,]+hm
dim(yay)
we8thereCounts
b[1,]
dim(matrix(b[2,]))
dim(matrix(y))
hm<- matrix(y) %*% t(matrix(b[2,])) ##    matrix(b[2,]) %*% t(matrix(y))
dim(hm)
hm + b[1,]
hm2 <- hm + b[1,]
dim(hm2)
length(hm2[,1])
length(hm2[1,])
hm2[1,] == hm[1,] + b[1,]
hm[1,]
b[1,]
head(hm)
b[2,2638]
b[1,]
b[1,] + hm[1,]
b[1,2638]
hm[1,2638]
(b[1,]+hm[1,])
(b[1,]+hm[1,])[2638]
dim(hm)
length(b[1,])
hm2 <- b[1,] + hm
hm2[1,2638]
b[1,2638] + hm[1,2638]
hm2 <- sweep(hm,MARGIN=2,b[1,],'*')
hm2[1,2638]
hm2 <- sweep(hm,MARGIN=2,b[1,],'+')
hm2[1,2638]
hm[1,2638]
b[1,2638]
b[1,2638]+hm[1,2638]
ll_left <- we8thereCounts%*%t(B[3:6,])   #this is still correct for the first part.
dim(ll_left)
Y[1,]
B[2,]
B[1,]
B[,1]
sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),MARGIN=2, B[1,],'+')
Y
B
t(B)
head(t(B))
help(sapply)
sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),MARGIN=2, B[1,],'+')
Y
B
B[,3]
dim(we8thereRatings)
dim(B)
Y
B
t(B[,3:6])
t(B[3:6,])
ll_penal <- sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),MARGIN=2, B[1,],'+') %*% t(B[3:6,])
dim(ll_penal)
head(ll_penal)
hm<-sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),MARGIN=2, B[1,],'+')  #Faster than sweep: t(t())? http://stackoverflow.com/questions/3643555/multiply-rows-of-matrix-by-vector
hm
Y[,1]
B[,1]
B[1,]
hist(B[1,])
hist(B[2,])
B[3:6,]
cust_sweep <- function(vector, matrix) { sweep(matrix,MARGIN=2,vector,'+')}
A <- matrix(1:9,nrow=3)
A
cust_sweep(A,-1:1)
sweep(A,MARGIN=1,c(1,2,3),"+")
sweep(A,MARGIN=2,c(1,2,3),"+")
cust_sweep <- function(vector, matrix) { sweep(matrix,MARGIN=2,vector,'+')}
cust_sweep(A,c(1,2,3))
vector
cust_sweep <- function(v, m) { sweep(matrix,MARGIN=2,vector,'+')}
cust_sweep(1:3,A)
cust_sweep(c(1,2,3),A)
cust_sweep
cust_sweep <- function(m,v) { sweep(m,MARGIN=2,v,'+')}
cust_sweep(A,1:3)
ll_penal <- cust_sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),B[1,])
Y[,1]%*%B[2,]
matrix(Y[,1])%*%B[2,]
B[2,]
dim(matrix(Y[,1]) %*% B[2,])
z <- array(1:24, dim = 2:4)
z
apply(B[3:6,],MARGIN=1,FUN=cust_sweep(ll_penal,x))
apply(B[3:6,],MARGIN=1,function(x) cust_sweep(ll_penal,x))
cust_sweep(ll_penal,B[4,])
rowSums(cust_sweep(ll_penal,B[4,]))
rowSums(cust_sweep(ll_penal,B[5,]))
apply(B[3:6,],MARGIN=1,function(x) rowSums(cust_sweep(ll_penal,x)))
cust_sweep(ll_penal,B[4,])
exp(cust_sweep(ll_penal,B[4,]))
apply(B[3:6,],MARGIN=1,function(x) rowSums(exp(cust_sweep(ll_penal,x))))
summary(apply(B[3:6,],MARGIN=1,function(x) rowSums(exp(cust_sweep(ll_penal,x)))))
ll_penal_tot <- apply(B[3:6,],MARGIN=1,function(x) log(rowSums(exp(cust_sweep(ll_penal,x)))))
ll_penal_tot
str(we8thereCounts)
help(dgCMatrix)
??dgCMatrix
we8thereCounts
rowSums(we8thereCounts)
ll_penal_tot
ll <- ll_penal_tot - ll_left
ll
m
m <- rowSums(we8thereCounts)
ll <- m*ll_penal_tot - ll_left
ll
## Iterating Cluster Membership and Parameter Values ##
# borrowing heavily from documentation: http://cran.r-project.org/web/packages/textir/textir.pdf
library(textir);data(we8there);cl <- NULL
#Initialize Cluster Membership randomly
cl_num<- as.factor(floor(runif(n=dim(we8thereRatings)[1],min=0,max=4)))
m <- rowSums(we8thereCounts)
# Notes: mnlm does not handle factors!
#Turn our factor (membership = 1,2 or 3) into vector (membership = [0 1 0]), etc
cl_matrix <- model.matrix(formula(~0+cl_num))
#Add clustermembership to the 'attributes' matrix so we can regress on it
Y<-Y_orig <- cbind(we8thereRatings[,'Overall',drop=FALSE],cl_matrix)
#Iterating loop. Takes a while
n.loop = 10
fits <- mnlm(cl,Y ,we8thereCounts, bins=5, gamma=1, nlambda=10); B <- coef(fits)  #
#Fit the model
B <- B_orig <- coef(fits) #Pull the coeffecients
for (i in 1:n.loop) {
ll_left <- we8thereCounts%*%t(B[3:6,])   #this is still correct for the first part.
#this produces an N x p matrix used for calculating penalization
hm<-sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),MARGIN=2, B[1,],'+')  #Faster than sweep: t(t())? http://stackoverflow.com/questions/3643555/multiply-rows-of-matrix-by-vector
#for each possible cluster, we want to add the cluster coeffecients to the intercept and y*beta term we already have
#the results should be an N x (#clusters) matrix
#so basically a repeated sweep!
cust_sweep <- function(m,v) { sweep(m,MARGIN=2,v,'+')}
ll_penal <- cust_sweep(matrix(Y[,1]) %*% B[2,] ,B[1,]) #add intercept and v_i term
ll_penal_tot <- apply(B[3:6,],MARGIN=1,function(x) log(rowSums(exp(cust_sweep(ll_penal,x)))))
ll <- m*ll_penal_tot - ll_left  #We cannot expect to be positive as we took out some common terms.
# check out cust_sweep(ll_penal,B[4,]) for an example of what's going on here
t(B[3:6,])
#Select new cluster membership if better.
n_cl <- as.factor(apply(ll,MARGIN=1,FUN=which.max)) #biased towards 1. Oh well.
n_cl_matrix <- model.matrix(formula(~0+(n_cl))) #and convert to [0 0 1] form.
#update our Y:
Y[,2:5] <- n_cl_matrixi
#And refit:
fits <- mnlm(cl,Y ,we8thereCounts, bins=5, gamma=1, nlambda=10); B <- coef(fits)  #
B <- B_orig <- coef(fits) #Pull the coeffecients
}
for (i in 1:n.loop) {
ll_left <- we8thereCounts%*%t(B[3:6,])   #this is still correct for the first part.
#this produces an N x p matrix used for calculating penalization
hm<-sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),MARGIN=2, B[1,],'+')  #Faster than sweep: t(t())? http://stackoverflow.com/questions/3643555/multiply-rows-of-matrix-by-vector
#for each possible cluster, we want to add the cluster coeffecients to the intercept and y*beta term we already have
#the results should be an N x (#clusters) matrix
#so basically a repeated sweep!
cust_sweep <- function(m,v) { sweep(m,MARGIN=2,v,'+')}
ll_penal <- cust_sweep(matrix(Y[,1]) %*% B[2,] ,B[1,]) #add intercept and v_i term
ll_penal_tot <- apply(B[3:6,],MARGIN=1,function(x) log(rowSums(exp(cust_sweep(ll_penal,x)))))
ll <- m*ll_penal_tot - ll_left  #We cannot expect to be positive as we took out some common terms.
# check out cust_sweep(ll_penal,B[4,]) for an example of what's going on here
t(B[3:6,])
#Select new cluster membership if better.
n_cl <- as.factor(apply(ll,MARGIN=1,FUN=which.max)) #biased towards 1. Oh well.
n_cl_matrix <- model.matrix(formula(~0+(n_cl))) #and convert to [0 0 1] form.
#update our Y:
Y[,2:5] <- n_cl_matrix
#And refit:
fits <- mnlm(cl,Y ,we8thereCounts, bins=5, gamma=1, nlambda=10); B <- coef(fits)  #
B <- B_orig <- coef(fits) #Pull the coeffecients
}
ll
n_cl
apply(ll,MARGIN=1,FUN=max)
cl_num<- as.factor(floor(runif(n=dim(we8thereRatings)[1],min=0,max=4)))
m <- rowSums(we8thereCounts)
# Notes: mnlm does not handle factors!
#Turn our factor (membership = 1,2 or 3) into vector (membership = [0 1 0]), etc
cl_matrix <- model.matrix(formula(~0+cl_num))
#Add clustermembership to the 'attributes' matrix so we can regress on it
Y<-Y_orig <- cbind(we8thereRatings[,'Overall',drop=FALSE],cl_matrix)
#Iterating loop. Takes a while
n.loop = 10
likes <- rep(NA,n.loop) #store likelihood updates here!
fits <- mnlm(cl,Y ,we8thereCounts, bins=5, gamma=1, nlambda=10); B <- coef(fits)  #
#Fit the model
B <- B_orig <- coef(fits) #Pull the coeffecients
for (i in 1:n.loop) {
ll_left <- we8thereCounts%*%t(B[3:6,])   #this is still correct for the first part.
#this produces an N x p matrix used for calculating penalization
hm<-sweep(matrix(Y[,1]) %*% t(matrix(B[2,])),MARGIN=2, B[1,],'+')  #Faster than sweep: t(t())? http://stackoverflow.com/questions/3643555/multiply-rows-of-matrix-by-vector
#for each possible cluster, we want to add the cluster coeffecients to the intercept and y*beta term we already have
#the results should be an N x (#clusters) matrix
#so basically a repeated sweep!
cust_sweep <- function(m,v) { sweep(m,MARGIN=2,v,'+')}
ll_penal <- cust_sweep(matrix(Y[,1]) %*% B[2,] ,B[1,]) #add intercept and v_i term
ll_penal_tot <- apply(B[3:6,],MARGIN=1,function(x) log(rowSums(exp(cust_sweep(ll_penal,x)))))
ll <- m*ll_penal_tot - ll_left  #We cannot expect to be positive as we took out some common terms.
# check out cust_sweep(ll_penal,B[4,]) for an example of what's going on here
#Select new cluster membership if better.
likes[i] <- sum(apply(ll,MARGIN=1,FUN=min))
n_cl <- as.factor(apply(ll,MARGIN=1,FUN=which.min)) #select cluster to minimize L
n_cl_matrix <- model.matrix(formula(~0+(n_cl))) #and convert to [0 0 1] form.
#update our Y:
Y[,2:5] <- n_cl_matrix
#And refit:
fits <- mnlm(cl,Y ,we8thereCounts, bins=5, gamma=1, nlambda=10); B <- coef(fits)  #
B <- B_orig <- coef(fits) #Pull the coeffecients
}
likes
plot(lies)
plot(likes)
library(ggplot)
library(ggplot2)
qplot(likes)
help(qplot)
qplot(likes,geom="line")
help(qplot)
qplot(1:10,likes)
help(qplot)
qplot(1:10,likes,xlab="iteration",ylab="log likelihood (relative)",main="MNIR with Clustering")
source(Iterate.R)
source('Iterate.R')
cl_num
cl_num<-sample(1:4,n=dim(we8thereRatings)[1],replace=TRUE)
help(sampe)
help(sample)
cl_num<-sample(1:4,size=dim(we8thereRatings)[1],replace=TRUE)
cl_num
list(1,2,3)
a = list(1,2)
b = list(1,a)
b
append
append(a,3)
b = append(a,3)
b[1]
b[]2 + 3
b[2] + 3
b[2][1] + 3
b[2][1]
b[2]
names(b)
names(b[2])
str(b)
b$
1
b$first
str(b)
str(b[1])
list(c(1,2,3,4))
b$first
b$hi
str(b)
c <- list(c(1,2,3,4),c(1,2))
c
str(c)
names(c) <- c("first", "second")
c
c$first
help(array)
array(,dim=2)
array(,dim=c(2,2))
help(mnlm)
library(MASS)
data(Cushings)
Cushings[,1:2] <- log(Cushings[,1:2])
Cushings
help(Cushings)
help(mnir)
help(mnlm)
train <- Cushings[Cushings$Type!="u",]
newdata <- as.matrix(Cushings[Cushings$Type == "u", 1:2])
newdata
fit <- mnlm(NULL,
covars=train[,1:2],
counts=factor(train$Type))
fit
coef(fit)
Cushings
round(coef(fit),1)
round(predict(fit, newdata, type="response"),1)
par(mfrow=c(1,3))
for(j in c("a","b","c")){
plot(fit[[j]]); mtext(j,line=2) }
source('Iterate.R')
library(textir);data(we8there);cl <- NULL
#Initialize Cluster Membership randomly
X = we8thereCounts
X
y = we8thereRatings['Overall']
y
library(textir);data(we8there);cl <- NULL
#Initialize Cluster Membership randomly
X = we8thereCounts
y = we8thereRatings['Overall']
clusters <- sample(1:4,size=dim(we8thereRatings)[1],replace=TRUE)
res<-iter_cluster(y,clusters,X,n.loop)
library(textir);data(we8there);cl <- NULL
#Initialize Cluster Membership randomly
#################################
X = we8thereCounts
y = we8thereRatings['Overall']
clusters <- sample(1:4,size=dim(we8thereRatings)[1],replace=TRUE)
n.loop = 10
#################################
res<-iter_cluster(y,clusters,X,n.loop)
source('Iterate.R')
######################################################################
###         Initialize  Cluster Membership                        ####
######################################################################
library(textir);data(we8there);cl <- NULL
#Initialize Cluster Membership randomly
#################################
X = we8thereCounts
y = we8thereRatings['Overall']
clusters <- sample(1:4,size=dim(we8thereRatings)[1],replace=TRUE)
n.loop = 10
#################################
res<-iter_cluster(y,clusters,X,n.loop)
#2:
names(res)
res
names(res)
res$likes
res$clusters
res$B
source('Iterate.R')
######################################################################
###         Initialize  Cluster Membership                        ####
######################################################################
library(textir);data(we8there);cl <- NULL
#Initialize Cluster Membership randomly
#################################
X = we8thereCounts
y = we8thereRatings['Overall']
clusters <- sample(1:4,size=dim(we8thereRatings)[1],replace=TRUE)
n.loop = 10
#################################
res<-iter_cluster(y,clusters,X,n.loop)
#TODO: Check that the log likelihood is actually higher:
qplot(1:10,likes,xlab="iteration",ylab="log likelihood (relative)",main="MNIR with Clustering")
#2:
res
error
n.loop = 2
res<-iter_cluster(y,clusters,X,n.loop)
source('Iterate.R')
######################################################################
###         Initialize  Cluster Membership                        ####
######################################################################
library(textir);data(we8there);cl <- NULL
#Initialize Cluster Membership randomly
#################################
X = we8thereCounts
y = we8thereRatings['Overall']
clusters <- sample(1:4,size=dim(we8thereRatings)[1],replace=TRUE)
n.loop = 2
#################################
res<-iter_cluster(y,clusters,X,n.loop)
#TODO: Check that the log likelihood is actually higher:
qplot(1:10,likes,xlab="iteration",ylab="log likelihood (relative)",main="MNIR with Clustering")
#2:
res
fits <- mnlm(cl, we8thereRatings[,'Overall',drop=FALSE],
we8thereCounts, bins=5, gamma=1, nlambda=10)
#baseline: how well does MNIR do?
## do MNIR projection onto factors
B <- coef(fits)
z <- srproj(B,we8thereCounts)
## fit a fwd model to the factors
summary(fwd <- lm(we8thereRatings$Overall ~ z))
## truncate the fwd predictions to our known range
fwd$fitted[fwd$fitted<1] <- 1
fwd$fitted[fwd$fitted>5] <- 5
## plot the fitted rating by true rating
par(mfrow=c(1,1))
plot(fwd$fitted ~ factor(we8thereRatings$Overall),
varwidth=TRUE, col="lightslategrey")
fwd$fitted
round(fwd$fitted)
fwd$fitted
head(round(fwd$fitted))
head(fwd$fitted)
tail(fwd$fitted)
tail(round(fwd$fitted))
tail(fwd$fitted)
round(fwd$fitted) == we8thereRatings$Overall
sum(round(fwd$fitted) == we8thereRatings$Overall)
sum(round(fwd$fitted) != we8thereRatings$Overall)
sum(round(fwd$fitted) != we8thereRatings$Overall)/length(we8thereRatings$Overall)
dim(res$B)
z2 <- srproj(res$B,we8thereCounts)
summary(fwd2 <- lm(we8thereRatings$Overall ~ z2))
## truncate the fwd predictions to our known range
fwd2$fitted[fwd2$fitted<1] <- 1
fwd2$fitted[fwd2$fitted>5] <- 5
## plot the fitted rating by true rating
par(mfrow=c(1,1))
plot(fwd$fitted ~ factor(we8thereRatings$Overall),
varwidth=TRUE, col="lightslategrey")
sum(round(fwd2$fitted) != we8thereRatings$Overall)/length(we8thereRatings$Overall)
#Initialize Cluster Membership randomly
#################################
X = we8thereCounts
y = we8thereRatings['Overall']
clusters <- sample(1:4,size=dim(we8thereRatings)[1],replace=TRUE)
n.loop = 15
#################################
res<-iter_cluster(y,clusters,X,n.loop)
z2 <- srproj(res$B,we8thereCounts)
summary(fwd2 <- lm(we8thereRatings$Overall ~ z2))
## truncate the fwd predictions to our known range
fwd2$fitted[fwd2$fitted<1] <- 1
fwd2$fitted[fwd2$fitted>5] <- 5
## plot the fitted rating by true rating
sum(round(fwd2$fitted) != we8thereRatings$Overall)/length(we8thereRatings$Overall)
